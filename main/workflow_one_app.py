import infinity_embedded as infinity
from infinity_embedded.common import ConflictType
from transformers import AutoModel,AutoTokenizer, AutoModelForSequenceClassification
import torch
import json
import pandas as pd
from tqdm import tqdm
import time as t
import logging
import os
import streamlit as st
from PIL import Image
from contextlib import contextmanager
import re

from utils import paper_only_author,paper_only_content,paper_author_content,text_to_image
from utils import chunk_hybid_search,chunk_hybid_search_with_paper,chunk_filter_paper,add_citations
from llm_api import deepseek_judge_rag,deepseek_daily_qa,kimi_decompose, deepseek_chat,deepseek_chat_refine
from llm_api import deepseek_judge_pc,kimi_paper_col,deepseek_rewrite,zhipu_image_query
from llm_api import deepseek_single_query,deepseek_sub_queries,deepseek_multi_step_queries

@contextmanager
def timer():
    start = t.time()
    yield lambda: t.time() - start


@st.cache_resource
def init():
    # åˆå§‹åŒ–
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = AutoModel.from_pretrained('autodl-tmp/models/jina-clip-v2', trust_remote_code=True)
    model = model.to(device)
    model.eval()

    rerank_model = AutoModelForSequenceClassification.from_pretrained('autodl-tmp/models/jina-reranker-v2-base-multilingual', trust_remote_code=True)
    rerank_model = rerank_model.to(device)
    rerank_model.eval()

    return model,rerank_model



# ä¸‹é¢æ˜¯æ•´ä½“çš„æµç¨‹
# æ£€ç´¢æµç¨‹
def retrieve(query, model, db_object,file, messages):
    """
    è¾“å…¥ï¼šç”¨æˆ·çš„æŸ¥è¯¢ï¼Œå‘é‡æ¨¡å‹ï¼Œæ•°æ®åº“ï¼Œæ£€ç´¢ç»“æœçš„ä¿å­˜å
    è¾“å‡ºï¼šé—®é¢˜ç±»å‹ï¼Œæ£€ç´¢ç»“æœ
    """
    # æ”¹å†™query
    try:
        rewrite = deepseek_rewrite(query, messages)
        rewrite = json.loads(rewrite).get("professional_query","")
        logging.info(f"æ­£åœ¨æ”¹å†™æŸ¥è¯¢ï¼Œæ”¹å†™åçš„æŸ¥è¯¢ï¼š{rewrite}")
        logging.info(f"æ”¹å†™æˆåŠŸï¼Œä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢æ‰§è¡Œchunkæ··åˆæ£€ç´¢å’Œä»¥æ–‡æœå›¾!")
        res,image_res,table_res = chunk_hybid_search(db_object, model, rewrite, 50, 0.7) # è¿”å›å®Œæ•´çš„chunkï¼Œå›¾ï¼Œè¡¨df
        
    except Exception as e:
        print("æ”¹å†™å¤±è´¥")
        logging.info(f"æ”¹å†™å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢æ‰§è¡Œchunkæ··åˆæ£€ç´¢å’Œä»¥æ–‡æœå›¾!\næŠ¥é”™ï¼š{e}")
        res,image_res,table_res = chunk_hybid_search(db_object, model, query, 50, 0.7) # df

    #image_res_1 = text_to_image(db_object, query, model) # ä»¥æ–‡æœå›¾ï¼Œä¸€å¼ 
    #image_res = pd.concat([image_res,image_res_1]) # åˆå¹¶
    
    # ä¿å­˜æ£€ç´¢çš„ç»“æœï¼Œè®¾ç½®ä¸ºæ—¥å¿—åŒåçš„csv
    retrieved_file_name = os.path.join("RAG/run/log", f'{file}')
    res.to_csv(f'{retrieved_file_name}.csv', index=False)
    
    logging.info(f"ä¿å­˜æ£€ç´¢ç»“æœå®Œæˆï¼Œå…±è®¡{len(res)}æ¡è®°å½•ï¼Œæ–‡ä»¶æ˜¯ï¼š{retrieved_file_name}")
    
    return res,image_res

# ç”Ÿæˆæµç¨‹
def generate(query,res,rerank_model,db_object,image_res, messages):
    """
    è¾“å…¥ï¼šç”¨æˆ·çš„æŸ¥è¯¢ï¼Œé—®é¢˜ç±»å‹ï¼Œæ£€ç´¢ç»“æœ, å­é—®é¢˜ï¼ˆå¯¹äºéå•ä¸€é—®é¢˜ï¼‰,chunkç›¸å…³çš„å›¾ç‰‡è¡¨ç»“æœï¼Œè¡¨æ ¼è¡¨ç»“æœ
    è¾“å‡ºï¼šç”Ÿæˆçš„å›å¤
    """
    
    logging.info("å¼€å§‹ç”Ÿæˆå›å¤ï¼")
    context = res['restored_content'].tolist() # ä¸Šä¸‹æ–‡
    # æ£€ç´¢è®ºæ–‡æ•°æ®ä½œä¸ºå‚è€ƒæ–‡çŒ®æ¥æº
    paper_uuids = res["paper_uuid"].drop_duplicates().tolist() # è®ºæ–‡id
    paper_res = chunk_filter_paper(db_object,paper_uuids)
    # æ ¹æ®è®ºæ–‡idåˆå¹¶è®ºæ–‡è¡¨å’Œchunkè¡¨ï¼Œä»¥chunkè¡¨ä¸ºåŸºå‡†
    merged_res = pd.merge(res, paper_res[['paper_uuid', 'title', 'author', 'file_path']], on="paper_uuid", how="left")
    merged_res['reference'] = merged_res['title'].astype(str) + ', ' + merged_res['author'].astype(str) # æ·»åŠ å¯¹åº”çš„è®ºæ–‡å‚è€ƒä¿¡æ¯
    # ç»„ç»‡æˆæ£€ç´¢ç»“æœ1,2,3ç­‰
    logging.info(f"ç»„ç»‡ä¸Šä¸‹æ–‡ä¸º['æ£€ç´¢ç»“æœ1':content]çš„æ ¼å¼ã€‚")
    contexts = []
    for idx,cont in enumerate(context):
        contexts.append(f"æ£€ç´¢ç»“æœ{idx+1}: {cont}")
    # æ‰¾åˆ°chunkçš„å›¾ç‰‡å’Œè¡¨æ ¼ï¼Œæ•°æ®åº“æ£€ç´¢
    images = image_res["image_path"].tolist()
    # tables = table_res["table_content"].tolist()
    # å›¾æ–‡çš„ï¼Œæ¨¡å‹ä¸è¡Œï¼Œä¸ç”¨
    # res = zhipu_image_query(query,contexts,image)
    # æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ— å¼•ç”¨å›å¤,çº¯æ–‡æœ¬çš„
    res = deepseek_chat(query, contexts, messages)

     # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹å…¬å¼å’Œè¡¨æ ¼
    formula_pattern = re.compile(r'\$[^$]*\$|\$\$[^$]*\$\$')  # æ£€æµ‹$...$æˆ–$$...$$
    table_pattern = re.compile(r'\|.*\|')  # æ£€æµ‹åŒ…å«|çš„è¡Œï¼Œé€šå¸¸ç”¨äºè¡¨æ ¼
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¬å¼æˆ–è¡¨æ ¼
    if formula_pattern.search(res) or table_pattern.search(res):
        # æ¶¦è‰²ï¼Œä½¿mdæ­£å¸¸
        res = deepseek_chat_refine(res)
    
    # æ·»åŠ å¼•ç”¨                                       # merged_res["restored_content"]
    final_answer, out_reference = add_citations(res, merged_res["chunk_content"].tolist(),merged_res["reference"].tolist(), rerank_model, 0.7)
    messages.append({"role": "user", "content": query})
    messages.append({"role": "assistant","content": res})
    
    return final_answer, out_reference, images

    
           

# åˆå§‹åŒ–æ—¥å¿—ï¼ˆå¯ä»¥åœ¨åŠ è½½æ¨¡å‹å’Œæ•°æ®åº“æ—¶é…ç½®ï¼‰
def init_logging(file_name="app_log"):
    log_file_path = os.path.join("RAG/run/log", f'{file_name}.log')
    os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        filename=log_file_path,
        filemode='w'
    )
    logger = logging.getLogger(__name__)
    logger.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆã€‚")
    return logger

@st.cache_resource
def get_database():
    print("åˆå§‹åŒ–æ•°æ®åº“è¿æ¥")
    infinity_object = infinity.connect("/root/RAG/database", config_path="/root/RAG/infinity_config/infinity_conf.toml")
    
    return infinity_object


# Streamlit åº”ç”¨
def main():

    st.set_page_config(page_title="å¤šæ¨¡æ€RAGå­¦æœ¯é—®ç­”ç³»ç»Ÿ", layout="wide")
    st.title("å¤šæ¨¡æ€å­¦æœ¯é—®ç­”ç³»ç»Ÿ")
    
    # åˆå§‹åŒ–æ—¥å¿—
    file = "test_1"
    logger = init_logging(file)

    # åˆå§‹åŒ–æ¨¡å‹
    with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
        model, rerank_model = init()

    # åˆå§‹åŒ–æ•°æ®åº“
    with st.spinner("æ­£åœ¨è¿æ¥æ•°æ®åº“..."):
        infinity_object = get_database()
        db_object = infinity_object.get_database("paper")

    # åˆå§‹åŒ–Session Stateä¸­çš„messageså’Œhistory
    if 'messages' not in st.session_state:
        system_prompt = """
            ä½ æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºè®ºæ–‡æé—®è®¾è®¡çš„åŠ©æ‰‹ï¼Œæ“…é•¿æ ¹æ®æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
            ä½ çš„å›ç­”åº”å½“åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿å‡†ç¡®æ€§å’Œç›¸å…³æ€§ã€‚
            é¿å…è¿‡åº¦è§£é‡Šæˆ–è„±ç¦»å®é™…çš„å†…å®¹ï¼Œå°½é‡ç®€æ´æ˜äº†ï¼Œèšç„¦äºç”¨æˆ·æé—®çš„å…·ä½“é—®é¢˜ã€‚
        """
        st.session_state.messages = [{"role": "system", "content": system_prompt}]
        st.session_state.history = []  # ç”¨äºå­˜å‚¨å†å²è®°å½•

    # ç»´æŠ¤å†å²ä¼šè¯é•¿åº¦
    if len(st.session_state.messages) >= 7:  # ä¾‹å¦‚ï¼Œé™åˆ¶æœ€å¤§æ¶ˆæ¯æ•°ä¸º6
        st.session_state.messages = st.session_state.messages[:1] + st.session_state.messages[-6:]

    # ä¾§è¾¹æ ï¼šæ˜¾ç¤º messages åˆ—è¡¨
    with st.sidebar:
        st.header("ğŸ”„ Messages")
        if st.session_state.messages[1:]:
            for idx, msg in enumerate(st.session_state.messages[1:], 1):
                st.markdown(f"**{msg['role'].capitalize()}:** {msg['content']}")
        else:
            st.write("æš‚æ— æ¶ˆæ¯ã€‚")

    # ä¸»ç•Œé¢
    st.write("è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢é—®é¢˜ï¼Œç„¶åç‚¹å‡»â€œæäº¤â€æŒ‰é’®è·å–å›ç­”ã€å‚è€ƒæ–‡çŒ®å’Œç›¸å…³å›¾ç‰‡ã€‚")

    query = st.text_input("ğŸ’¬ æŸ¥è¯¢é—®é¢˜", "äº‹ç†å›¾è°±çš„åŸç†æ˜¯ä»€ä¹ˆ?")

    if st.button("æäº¤"):
        if query.strip() == "":
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„æŸ¥è¯¢é—®é¢˜ã€‚")
        else:
            with st.spinner("ç³»ç»Ÿå¤„ç†ä¸­..."):
                # æ˜¾ç¤ºè¿›åº¦æ¡
                progress_bar = st.progress(0)
                # æ‰§è¡Œæ£€ç´¢
                progress_bar.progress(10)
                with timer() as get_retrieve_time:
                    res, image_res = retrieve(query, model, db_object, file, st.session_state.messages)
                    retrieve_time = get_retrieve_time()
                progress_bar.progress(50)

                # æ‰§è¡Œç”Ÿæˆ
                with timer() as get_generate_time:
                    answer, reference, images = generate(query, res, rerank_model, db_object, image_res, st.session_state.messages)
                    generate_time = get_generate_time()
                progress_bar.progress(100)
                t.sleep(0.5)  # ç¡®ä¿è¿›åº¦æ¡æ˜¾ç¤ºåˆ°100%

                # å…³é—­è¿›åº¦æ¡
                progress_bar.empty()

            # æ›´æ–°å†å²è®°å½•
            st.session_state.history.append({
                    "query": query,
                    "answer": answer,
                    "reference": reference,
                    "images": images
                })

            # ä½¿ç”¨ st.chat_message æ˜¾ç¤ºå¯¹è¯ï¼ˆä» history ä¸­è·å–å¸¦å¼•ç”¨çš„å›ç­”ï¼‰
            st.markdown("### ğŸ—¨ï¸ å½“å‰ä¼šè¯")
            for record in st.session_state.history:
                with st.chat_message("user"):
                    st.write(record["query"])
                with st.chat_message("assistant"):
                    st.write(record['answer'])

            st.subheader("ğŸ“š å‚è€ƒæ–‡çŒ®")
            if reference:
                st.markdown("\n\n".join(reference))
            else:
                st.write("æ— å‚è€ƒæ–‡çŒ®ã€‚")

            st.subheader("ğŸ–¼ï¸ ç›¸å…³å›¾ç‰‡")
            if images:
                cols = st.columns(3)
                for idx, img_path in enumerate(images):
                    if os.path.exists(img_path):
                        img = Image.open(img_path)
                        cols[idx % 3].image(img, use_container_width=True)
                    else:
                        cols[idx % 3].write(f"å›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨ï¼š{img_path}")
            else:
                st.write("æ— ç›¸å…³å›¾ç‰‡ã€‚")


            # æ˜¾ç¤ºè€—æ—¶ä¿¡æ¯
            st.markdown(f"**æ£€ç´¢è€—æ—¶**: {retrieve_time:.2f} ç§’")
            st.markdown(f"**ç”Ÿæˆè€—æ—¶**: {generate_time:.2f} ç§’")
            st.markdown("---")  # åˆ†éš”çº¿

    
    

if __name__ == "__main__":

    main()